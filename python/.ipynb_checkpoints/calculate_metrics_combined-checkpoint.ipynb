{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autoscrolling long output is disabled\n",
      "(96681, 192, 192, 1) (96681, 192, 192, 1) 96681\n",
      "data shapes, test=(96681, 192, 192, 1),(96681, 192, 192, 1)\n",
      "42694\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import modules.layers as tf_util\n",
    "import modules.utility as util\n",
    "import numpy as np\n",
    "import tables\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import rotate\n",
    "from IPython.display import display, Javascript\n",
    "import json\n",
    "\n",
    "disable_js = \"\"\"\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def disable_scroll():\n",
    "    display(Javascript(disable_js))\n",
    "    print (\"autoscrolling long output is disabled\")\n",
    "    \n",
    "disable_scroll()\n",
    "\n",
    "###############################\n",
    "# Load Param File\n",
    "###############################\n",
    "def parse_json(json_file):\n",
    "    with open(json_file) as f:\n",
    "      attrs = json.load(f)\n",
    "      params = {}\n",
    "    for k, v in attrs.iteritems(): params[k] = v\n",
    "\n",
    "    return params\n",
    "\n",
    "\n",
    "CONFIG_FILE = './config/ct.json'\n",
    "#CONFIG_FILE = './config/mr.json'\n",
    "#CONFIG_FILE = './config/combined.json'\n",
    "#CONFIG_FILE  = './config/pulmonary.json'\n",
    "\n",
    "CONFIG = parse_json(CONFIG_FILE)\n",
    "MODE   = CONFIG['MODE']\n",
    "util.mkdir(CONFIG['OUTPUT_PATH'])\n",
    "if CONFIG.has_key('MODEL_DIR'):\n",
    "    MODEL_DIR = CONFIG['MODEL_DIR']\n",
    "else:\n",
    "    MODEL_DIR = CONFIG['OUTPUT_PATH']+'/model/i2i'\n",
    "\n",
    "IMAGES_DIR = CONFIG['OUTPUT_PATH']+'/predictions'\n",
    "#TODO: SAVING + RESULTS\n",
    "\n",
    "#######################################################\n",
    "# Get data\n",
    "#######################################################\n",
    "#CT Dataset\n",
    "data_path = '/media/marsdenlab/Data2/datasets/DeepLofting/'\n",
    "    \n",
    "test = data_path+'test_192_combined.hdf5'\n",
    "\n",
    "MODEL_CODE = 'ALL'    \n",
    "\n",
    "names_test = open('ct_test_list.txt').readlines()\n",
    "\n",
    "names_test   = names_test + open('mr_test_list.txt').readlines()\n",
    "\n",
    "f_test = tables.open_file(test)\n",
    "\n",
    "input_shape = f_test.root.X.shape\n",
    "output_shape = f_test.root.Y.shape\n",
    "print input_shape, output_shape, len(names_test)\n",
    "\n",
    "print 'data shapes, test={},{}'.format(input_shape,output_shape)\n",
    "\n",
    "if CONFIG.has_key('TEST_IMAGES'):\n",
    "    INDS_TEST = [i for i in range(input_shape[0]) if any(c in names_test[i] for c in CONFIG['TEST_IMAGES'])]\n",
    "else:\n",
    "    INDS_TEST = range(input_shape[0])\n",
    "print len(INDS_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################################################\n",
    "# Define variables\n",
    "######################################################\n",
    "N = f_test.root.X.shape[0]\n",
    "W,H,C = f_test.root.X[0].shape\n",
    "C=1\n",
    "crop_dims = 128\n",
    "Nbatch = 16\n",
    "lr = 1e-5\n",
    "Nsteps=40000\n",
    "print_step=200\n",
    "init = 7e-2\n",
    "lam = 0.001\n",
    "Nfilters = 32\n",
    "\n",
    "EPS=1e-4\n",
    "leaky_relu = tf.contrib.keras.layers.LeakyReLU(0.2)\n",
    "y_index=0\n",
    "alph = 0.3\n",
    "beta = 0.7\n",
    "THRESHOLD = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 16384]\n",
      "[16, 16384]\n",
      "Tensor(\"Sigmoid_1:0\", shape=(16, 128, 128, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def selu(x):\n",
    "    with ops.name_scope('elu') as scope:\n",
    "        alpha = 1.6732632423543772848170429916717\n",
    "        scale = 1.0507009873554804934193349852946\n",
    "    return scale*tf.where(x>=0.0, x, alpha*tf.nn.elu(x)-alpha)\n",
    "#########################################################\n",
    "# Define graph\n",
    "#########################################################\n",
    "x = tf.placeholder(shape=[None,crop_dims,crop_dims,C],dtype=tf.float32)\n",
    "y = tf.placeholder(shape=[None,crop_dims,crop_dims,C],dtype=tf.float32)\n",
    "\n",
    "yclass,yhat,o3,o4 = tf_util.I2INet(x,nfilters=Nfilters,activation=leaky_relu,init=init)\n",
    "\n",
    "y_vec = tf.reshape(yhat, (Nbatch,crop_dims**2))\n",
    "\n",
    "sp = tf_util.fullyConnected(y_vec,crop_dims,leaky_relu, std='xavier', scope='sp1')\n",
    "sp = tf_util.fullyConnected(y_vec,crop_dims**2,leaky_relu, std='xavier', scope='sp2')\n",
    "sp = tf.reshape(sp, (Nbatch,crop_dims,crop_dims,1))\n",
    "\n",
    "y_sp = tf_util.conv2D(sp, nfilters=Nfilters, activation=leaky_relu,init=init, scope='sp3')\n",
    "y_sp_1 = tf_util.conv2D(y_sp, nfilters=Nfilters, activation=leaky_relu, init=init,scope='sp4')\n",
    "y_sp_2 = tf_util.conv2D(y_sp_1, nfilters=Nfilters, activation=leaky_relu, init=init,scope='sp5')\n",
    "\n",
    "yhat = tf_util.conv2D(y_sp_2, nfilters=1, activation=tf.identity, init=init,scope='sp6')\n",
    "\n",
    "yclass = tf.sigmoid(yhat)\n",
    "\n",
    "# loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=yhat,labels=y))\n",
    "\n",
    "# loss = loss + tf_util.l2_reg(lam)\n",
    "\n",
    "# opt = tf.train.AdamOptimizer(lr)\n",
    "# train = opt.minimize(loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print yclass\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/marsdenlab/projects/DeepLofting/python/models/i2i_CT/i2i_CT\n"
     ]
    }
   ],
   "source": [
    "saver.restore(sess,MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96681\n",
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "8000\n",
      "10000\n",
      "12000\n",
      "14000\n",
      "16000\n",
      "18000\n",
      "20000\n",
      "22000\n",
      "24000\n",
      "26000\n",
      "28000\n",
      "30000\n",
      "32000\n",
      "34000\n",
      "36000\n",
      "38000\n",
      "40000\n",
      "42000\n",
      "44000\n",
      "46000\n",
      "48000\n",
      "50000\n",
      "52000\n",
      "54000\n",
      "56000\n",
      "58000\n",
      "60000\n",
      "62000\n",
      "64000\n",
      "66000\n",
      "68000\n",
      "70000\n",
      "72000\n",
      "74000\n",
      "76000\n",
      "78000\n",
      "80000\n",
      "82000\n",
      "84000\n",
      "86000\n",
      "88000\n",
      "90000\n",
      "92000\n",
      "94000\n",
      "96000\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "N=f_test.root.X.shape[0]\n",
    "print N\n",
    "ypred=np.zeros((N,crop_dims,crop_dims,1)).astype(float)\n",
    "ytrue=np.zeros((N,crop_dims,crop_dims,1)).astype(float)\n",
    "\n",
    "for i in range(0,N,Nbatch):\n",
    "    if i%1000 == 0:\n",
    "        print i\n",
    "    xb = util.crop_center_nd(f_test.root.X[i:i+Nbatch], \n",
    "                                crop_dims,crop_dims)\n",
    "    yb = util.crop_center_nd(f_test.root.Y[i:i+Nbatch],\n",
    "                                crop_dims, crop_dims)\n",
    "    a = Nbatch\n",
    "    if xb.shape[0] < Nbatch:\n",
    "        a = xb.shape[0]\n",
    "        print a\n",
    "        tempx = np.zeros((Nbatch,crop_dims,crop_dims,1))\n",
    "        tempy = np.zeros((Nbatch,crop_dims,crop_dims,1))\n",
    "        \n",
    "        tempx[:xb.shape[0]] = xb.copy()\n",
    "        tempy[:xb.shape[0]] = yb.copy()\n",
    "        \n",
    "        xb = tempx.copy()\n",
    "        yb = tempy.copy()\n",
    "    yout =sess.run(yclass,{x:xb,y:yb})\n",
    "    \n",
    "    if a < Nbatch:\n",
    "        ypred[i:i+Nbatch] = yout[:a].copy()\n",
    "        ytrue[i:i+Nbatch] = yb[:a].copy()\n",
    "\n",
    "    else:\n",
    "        ypred[i:i+Nbatch] = yout.copy()\n",
    "        ytrue[i:i+Nbatch] = yb.copy()\n",
    "\n",
    "np.save(CONFIG['OUTPUT_PATH']+'/i2i_segs.npy',ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "8000\n",
      "10000\n",
      "12000\n",
      "14000\n",
      "16000\n",
      "18000\n",
      "20000\n",
      "22000\n",
      "24000\n",
      "26000\n",
      "28000\n",
      "30000\n",
      "32000\n",
      "34000\n",
      "36000\n",
      "38000\n",
      "40000\n",
      "42000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from medpy.metric.binary import hd, assd, dc, precision\n",
    "df_results = pd.DataFrame()\n",
    "\n",
    "ypred = np.load(CONFIG['OUTPUT_PATH']+'/i2i_segs.npy')\n",
    "for i in INDS_TEST:\n",
    "    y = util.threshold(ypred[i],THRESHOLD)[:,:,0].astype(int)\n",
    "    y_truth = f_test.root.Y[i,:,:,0].astype(int)\n",
    "    y_truth = util.crop_center(y_truth,crop_dims,crop_dims)\n",
    "\n",
    "    if i%2000 == 0:\n",
    "        print i\n",
    "\n",
    "    e_hd = hd(y, y_truth, f_test.root.meta[i][0])\n",
    "\n",
    "        \n",
    "    e_assd = assd(y,y_truth,f_test.root.meta[i][0])\n",
    "\n",
    "    TP = np.sum(y_truth*y)\n",
    "    FP = np.sum((1.0-y_truth)*y)\n",
    "    TN = np.sum((1.0-y_truth)*(1.0-y))\n",
    "    FN = np.sum(y_truth*(1.0-y))\n",
    "    \n",
    "    image = names_test[i].split('_')[0]\n",
    "    group = names_test[i].split(',')[1]\n",
    "    point = names_test[i].split(',')[2]\n",
    "    \n",
    "    d = {'image':image, 'group':group, 'point':point, 'TP':TP,'FP':FP,\n",
    "         'TN':TN,'FN':FN,'ASSD':e_assd,'hausdorff':e_hd}\n",
    "    df_results = df_results.append(d,ignore_index=True)\n",
    "df_results.to_csv(CONFIG['OUTPUT_PATH']+'/results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marsdenlab/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:7: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "def df_dice(grp):\n",
    "    # sum columns\n",
    "    grp = grp[['TP', 'TN', 'FP', 'FN']].sum()\n",
    "\n",
    "    return 2*grp['TP']/(2*grp['TP']+grp['FP']+grp['FN'])\n",
    "\n",
    "mr_images = ['0006', '0080', '0082', '0101', '0171', '0178', '0110']\n",
    "ct_images = ['0004', '0177', 'cabg11', '0179', '0144', '0148', '0150', '0119']\n",
    "\n",
    "df = pd.read_csv(CONFIG['OUTPUT_PATH']+'/results.csv')\n",
    "\n",
    "df = df.loc[df.hausdorff > -1]\n",
    "df = df.loc[df.ASSD > -1]\n",
    "\n",
    "df.loc[df.image.isin(ct_images), 'type'] = 'CT'\n",
    "df.loc[df.image.isin(mr_images), 'type'] = 'MR'\n",
    "df.loc[:,'code'] = 'all'\n",
    "dfs = OrderedDict()\n",
    "\n",
    "# dfs['DICE'] = pd.concat([df.groupby(['type']).apply(df_dice).to_frame().T,\n",
    "#                         df.groupby(['code']).apply(df_dice).to_frame().T.rename(columns={'all':'Overall'})],\n",
    "#                          axis=1)\n",
    "\n",
    "dfs['DICE'] = pd.DataFrame({'CT':df_dice(df.loc[df.type=='CT']),'MR':df_dice(df.loc[df.type=='MR']),\n",
    "               'Overall':df_dice(df.loc[:])},index=[0])\n",
    "\n",
    "for k in ['ASSD', 'hausdorff']:\n",
    "#     dfs[k] = pd.concat([df.groupby(['type']).mean()[k].to_frame().T,\n",
    "#                         df.groupby(['code']).mean()[k].to_frame().T.rename(columns={'all':'Overall'})],\n",
    "#                        axis=1)\n",
    "\n",
    "      dfs[k] = pd.DataFrame({'CT':df.loc[df.type=='CT',k].mean(),\n",
    "                'MR':df.loc[df.type=='MR',k].mean(),\n",
    "                'Overall':df.loc[:,k].mean()},index=[0])\n",
    "out_df = pd.concat(dfs.values(), keys=dfs.keys(), axis=1).sort_values(('DICE', 'Overall'), \n",
    "                                                                          ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      DICE                     ASSD                 hausdorff                \n",
      "        CT     MR  Overall       CT     MR  Overall        CT     MR  Overall\n",
      "0  $0.579$  $nan$  $0.579$  $0.126$  $nan$  $0.126$   $0.382$  $nan$  $0.382$\n"
     ]
    }
   ],
   "source": [
    "print out_df.applymap(lambda x: \"${:.3f}$\".format(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "print f_test.root.Y[INDS_TEST,:,:,0].shape\n",
    "print ypred[INDS_TEST].shape\n",
    "pr = precision_recall_curve(np.ravel(\n",
    "    util.crop_center_nd(f_test.root.Y[INDS_TEST,:,:,0],crop_dims,crop_dims)).astype(int),\n",
    "                            np.ravel(ypred[INDS_TEST]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
